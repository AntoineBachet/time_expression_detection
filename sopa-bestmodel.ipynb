{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "import tensorboardX\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"sopa_master/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import read_embeddings, read_docs, read_labels\n",
    "from soft_patterns import ProbSemiring, MaxPlusSemiring, LogSpaceMaxTimesSemiring, SoftPatternClassifier, train, Batch, evaluate_accuracy\n",
    "from util import to_cuda\n",
    "from interpret_classification_results import interpret_documents\n",
    "from visualize import visualize_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"data/time_data_clean/train.data\"\n",
    "train_label_file =\"data/time_data_clean/train.labels\"\n",
    "dev_data_file = \"data/time_data_clean/dev.data\"\n",
    "dev_label_file = \"data/time_data_clean/dev.labels\"\n",
    "test_file = \"data/time_data_clean/test.data\"\n",
    "test_label=\"data/time_data_clean/test.labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = \"7-10_6-10_5-10_4-10_3-10_2-10\"\n",
    "pattern_specs = OrderedDict(sorted(([int(y) for y in x.split(\"-\")] for x in patterns.split(\"_\")),\n",
    "                                key=lambda t: t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_padding_tokens=max(list(pattern_specs.keys())) - 1\n",
    "num_padding_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pickle.load(open(\"data/embeddings/vocab.p\",\"rb\"))\n",
    "embeddings = pickle.load(open(\"data/embeddings/embeddings.p\",\"rb\"))\n",
    "word_dim = pickle.load(open(\"data/embeddings/word_dim.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 OrderedDict([(2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10)])\n",
      "# params: 256727\n"
     ]
    }
   ],
   "source": [
    "model = SoftPatternClassifier(\n",
    "    pattern_specs=pattern_specs,\n",
    "    mlp_hidden_dim=25,\n",
    "    num_mlp_layers=5,\n",
    "    num_classes=2,\n",
    "    embeddings=embeddings,\n",
    "    vocab=vocab,\n",
    "    semiring=LogSpaceMaxTimesSemiring,\n",
    "    bias_scale_param=1,\n",
    "    shared_sl=False,\n",
    "    no_sl=False,\n",
    "    no_eps=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_text = read_docs(train_data_file, vocab, num_padding_tokens=num_padding_tokens)\n",
    "train_labels = read_labels(train_label_file)\n",
    "dev_input, dev_text = read_docs(dev_data_file, vocab, num_padding_tokens=num_padding_tokens)\n",
    "dev_labels = read_labels(dev_label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_input, train_labels))\n",
    "dev_data = list(zip(dev_input, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................\n",
      "\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      426\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      217\n",
      "iteration:       0 train time:     0.133m, eval time:     0.014m train loss:        0.685 train_acc:   57.400% dev loss:        0.675 dev_acc:   60.545%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to data/models/modelstime/best_sopa_0.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      420\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      217\n",
      "iteration:       1 train time:     0.276m, eval time:     0.015m train loss:        0.682 train_acc:   58.000% dev loss:        0.671 dev_acc:   60.545%\n",
      "New best dev!\n",
      "saving model to data/models/modelstime/best_sopa_1.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      403\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      217\n",
      "iteration:       2 train time:     0.418m, eval time:     0.015m train loss:        0.681 train_acc:   59.700% dev loss:        0.671 dev_acc:   60.545%\n",
      "New best dev!\n",
      "saving model to data/models/modelstime/best_sopa_2.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      409\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      217\n",
      "iteration:       3 train time:     0.560m, eval time:     0.015m train loss:        0.678 train_acc:   59.100% dev loss:        0.658 dev_acc:   60.545%\n",
      "New best dev!\n",
      "saving model to data/models/modelstime/best_sopa_3.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 309\n",
      "num gold 1s:      428\n",
      "num predicted 1s: 158\n",
      "num gold 1s:      217\n",
      "iteration:       4 train time:     0.705m, eval time:     0.013m train loss:        0.628 train_acc:   81.300% dev loss:        0.531 dev_acc:   81.636%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to data/models/modelstime/best_sopa_4.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 419\n",
      "num gold 1s:      432\n",
      "num predicted 1s: 225\n",
      "num gold 1s:      217\n",
      "iteration:       5 train time:     0.845m, eval time:     0.014m train loss:        0.476 train_acc:   83.100% dev loss:        0.407 dev_acc:   82.545%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to data/models/modelstime/best_sopa_5.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 449\n",
      "num gold 1s:      434\n",
      "num predicted 1s: 223\n",
      "num gold 1s:      217\n",
      "iteration:       6 train time:     0.989m, eval time:     0.014m train loss:        0.384 train_acc:   85.500% dev loss:        0.394 dev_acc:   83.636%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to data/models/modelstime/best_sopa_6.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 428\n",
      "num gold 1s:      427\n",
      "num predicted 1s: 220\n",
      "num gold 1s:      217\n",
      "iteration:       7 train time:     1.133m, eval time:     0.013m train loss:        0.364 train_acc:   86.900% dev loss:        0.379 dev_acc:   84.182%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to data/models/modelstime/best_sopa_7.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 371\n",
      "num gold 1s:      415\n",
      "num predicted 1s: 191\n",
      "num gold 1s:      217\n",
      "iteration:       8 train time:     1.276m, eval time:     0.014m train loss:        0.317 train_acc:   90.000% dev loss:        0.360 dev_acc:   85.818%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to data/models/modelstime/best_sopa_8.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 460\n",
      "num gold 1s:      426\n",
      "num predicted 1s: 237\n",
      "num gold 1s:      217\n",
      "iteration:       9 train time:     1.422m, eval time:     0.015m train loss:        0.275 train_acc:   91.200% dev loss:        0.383 dev_acc:   84.000%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 370\n",
      "num gold 1s:      398\n",
      "num predicted 1s: 196\n",
      "num gold 1s:      217\n",
      "iteration:      10 train time:     1.564m, eval time:     0.017m train loss:        0.247 train_acc:   92.200% dev loss:        0.355 dev_acc:   87.455%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to data/models/modelstime/best_sopa_10.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 339\n",
      "num gold 1s:      425\n",
      "num predicted 1s: 145\n",
      "num gold 1s:      217\n",
      "iteration:      11 train time:     1.710m, eval time:     0.015m train loss:        0.232 train_acc:   89.800% dev loss:        0.478 dev_acc:   83.273%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 426\n",
      "num gold 1s:      421\n",
      "num predicted 1s: 218\n",
      "num gold 1s:      217\n",
      "iteration:      12 train time:     1.855m, eval time:     0.014m train loss:        0.216 train_acc:   94.900% dev loss:        0.359 dev_acc:   85.273%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 458\n",
      "num gold 1s:      441\n",
      "num predicted 1s: 235\n",
      "num gold 1s:      217\n",
      "iteration:      13 train time:     2.009m, eval time:     0.016m train loss:        0.167 train_acc:   96.100% dev loss:        0.382 dev_acc:   84.364%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 422\n",
      "num gold 1s:      425\n",
      "num predicted 1s: 198\n",
      "num gold 1s:      217\n",
      "iteration:      14 train time:     2.173m, eval time:     0.014m train loss:        0.137 train_acc:   97.100% dev loss:        0.386 dev_acc:   87.818%\n",
      "New best acc!\n",
      "saving model to data/models/modelstime/best_sopa_14.pth\n",
      "...................\n",
      "\n",
      "num predicted 1s: 430\n",
      "num gold 1s:      432\n",
      "num predicted 1s: 197\n",
      "num gold 1s:      217\n",
      "iteration:      15 train time:     2.325m, eval time:     0.015m train loss:        0.088 train_acc:   98.800% dev loss:        0.406 dev_acc:   87.636%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 433\n",
      "num gold 1s:      431\n",
      "num predicted 1s: 212\n",
      "num gold 1s:      217\n",
      "iteration:      16 train time:     2.479m, eval time:     0.014m train loss:        0.055 train_acc:   99.400% dev loss:        0.427 dev_acc:   86.364%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 424\n",
      "num gold 1s:      418\n",
      "num predicted 1s: 240\n",
      "num gold 1s:      217\n",
      "iteration:      17 train time:     2.623m, eval time:     0.016m train loss:        0.034 train_acc:   99.400% dev loss:        0.472 dev_acc:   83.818%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 409\n",
      "num gold 1s:      408\n",
      "num predicted 1s: 170\n",
      "num gold 1s:      217\n",
      "iteration:      18 train time:     2.770m, eval time:     0.015m train loss:        0.031 train_acc:   99.700% dev loss:        0.582 dev_acc:   86.364%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 427\n",
      "num gold 1s:      425\n",
      "num predicted 1s: 253\n",
      "num gold 1s:      217\n",
      "iteration:      19 train time:     2.927m, eval time:     0.019m train loss:        0.021 train_acc:   99.800% dev loss:        0.573 dev_acc:   83.636%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 422\n",
      "num gold 1s:      423\n",
      "num predicted 1s: 188\n",
      "num gold 1s:      217\n",
      "iteration:      20 train time:     3.091m, eval time:     0.016m train loss:        0.017 train_acc:   99.900% dev loss:        0.605 dev_acc:   86.000%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 438\n",
      "num gold 1s:      438\n",
      "num predicted 1s: 176\n",
      "num gold 1s:      217\n",
      "iteration:      21 train time:     3.239m, eval time:     0.014m train loss:        0.009 train_acc:   99.800% dev loss:        0.668 dev_acc:   85.636%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 420\n",
      "num gold 1s:      420\n",
      "num predicted 1s: 197\n",
      "num gold 1s:      217\n",
      "iteration:      22 train time:     3.385m, eval time:     0.014m train loss:        0.007 train_acc:  100.000% dev loss:        0.629 dev_acc:   86.182%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 430\n",
      "num gold 1s:      429\n",
      "num predicted 1s: 231\n",
      "num gold 1s:      217\n",
      "iteration:      23 train time:     3.529m, eval time:     0.014m train loss:        0.005 train_acc:   99.900% dev loss:        0.629 dev_acc:   84.000%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 426\n",
      "num gold 1s:      426\n",
      "num predicted 1s: 205\n",
      "num gold 1s:      217\n",
      "iteration:      24 train time:     3.679m, eval time:     0.014m train loss:        0.004 train_acc:  100.000% dev loss:        0.647 dev_acc:   85.455%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 412\n",
      "num gold 1s:      412\n",
      "num predicted 1s: 177\n",
      "num gold 1s:      217\n",
      "iteration:      25 train time:     3.826m, eval time:     0.016m train loss:        0.002 train_acc:  100.000% dev loss:        0.722 dev_acc:   85.455%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 407\n",
      "num gold 1s:      407\n",
      "num predicted 1s: 187\n",
      "num gold 1s:      217\n",
      "iteration:      26 train time:     3.973m, eval time:     0.016m train loss:        0.002 train_acc:  100.000% dev loss:        0.707 dev_acc:   85.818%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 428\n",
      "num gold 1s:      428\n",
      "num predicted 1s: 230\n",
      "num gold 1s:      217\n",
      "iteration:      27 train time:     4.120m, eval time:     0.016m train loss:        0.001 train_acc:  100.000% dev loss:        0.678 dev_acc:   84.545%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 434\n",
      "num gold 1s:      434\n",
      "num predicted 1s: 202\n",
      "num gold 1s:      217\n",
      "iteration:      28 train time:     4.267m, eval time:     0.015m train loss:        0.001 train_acc:  100.000% dev loss:        0.702 dev_acc:   84.909%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 439\n",
      "num gold 1s:      439\n",
      "num predicted 1s: 209\n",
      "num gold 1s:      217\n",
      "iteration:      29 train time:     4.415m, eval time:     0.015m train loss:        0.000 train_acc:  100.000% dev loss:        0.702 dev_acc:   84.727%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 433\n",
      "num gold 1s:      433\n",
      "num predicted 1s: 212\n",
      "num gold 1s:      217\n",
      "iteration:      30 train time:     4.584m, eval time:     0.017m train loss:        0.000 train_acc:  100.000% dev loss:        0.709 dev_acc:   84.909%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 430\n",
      "num gold 1s:      430\n",
      "num predicted 1s: 209\n",
      "num gold 1s:      217\n",
      "iteration:      31 train time:     4.748m, eval time:     0.015m train loss:        0.000 train_acc:  100.000% dev loss:        0.720 dev_acc:   84.727%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 430\n",
      "num gold 1s:      430\n",
      "num predicted 1s: 211\n",
      "num gold 1s:      217\n",
      "iteration:      32 train time:     4.900m, eval time:     0.014m train loss:        0.000 train_acc:  100.000% dev loss:        0.726 dev_acc:   85.091%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 432\n",
      "num gold 1s:      432\n",
      "num predicted 1s: 212\n",
      "num gold 1s:      217\n",
      "iteration:      33 train time:     5.047m, eval time:     0.014m train loss:        0.000 train_acc:  100.000% dev loss:        0.732 dev_acc:   84.909%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 429\n",
      "num gold 1s:      429\n",
      "num predicted 1s: 213\n",
      "num gold 1s:      217\n",
      "iteration:      34 train time:     5.193m, eval time:     0.018m train loss:        0.000 train_acc:  100.000% dev loss:        0.738 dev_acc:   85.091%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 419\n",
      "num gold 1s:      419\n",
      "num predicted 1s: 209\n",
      "num gold 1s:      217\n",
      "iteration:      35 train time:     5.343m, eval time:     0.015m train loss:        0.000 train_acc:  100.000% dev loss:        0.748 dev_acc:   84.727%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 407\n",
      "num gold 1s:      407\n",
      "num predicted 1s: 211\n",
      "num gold 1s:      217\n",
      "iteration:      36 train time:     5.499m, eval time:     0.018m train loss:        0.000 train_acc:  100.000% dev loss:        0.751 dev_acc:   85.091%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 408\n",
      "num gold 1s:      408\n",
      "num predicted 1s: 211\n",
      "num gold 1s:      217\n",
      "iteration:      37 train time:     5.652m, eval time:     0.018m train loss:        0.000 train_acc:  100.000% dev loss:        0.757 dev_acc:   85.091%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 425\n",
      "num gold 1s:      425\n",
      "num predicted 1s: 213\n",
      "num gold 1s:      217\n",
      "iteration:      38 train time:     5.807m, eval time:     0.020m train loss:        0.000 train_acc:  100.000% dev loss:        0.761 dev_acc:   85.091%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 430\n",
      "num gold 1s:      430\n",
      "num predicted 1s: 209\n",
      "num gold 1s:      217\n",
      "iteration:      39 train time:     5.974m, eval time:     0.014m train loss:        0.000 train_acc:  100.000% dev loss:        0.769 dev_acc:   84.727%\n",
      "...................\n",
      "\n",
      "num predicted 1s: 439\n",
      "num gold 1s:      439\n",
      "num predicted 1s: 212\n",
      "num gold 1s:      217\n",
      "iteration:      40 train time:     6.119m, eval time:     0.016m train loss:        0.000 train_acc:  100.000% dev loss:        0.772 dev_acc:   85.273%\n",
      "Reached 30 iterations without improving dev loss. Breaking\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SoftPatternClassifier (\n",
       "  (mlp): MLP (\n",
       "    (layers): ModuleList (\n",
       "      (0): Linear (60 -> 25)\n",
       "      (1): Linear (25 -> 25)\n",
       "      (2): Linear (25 -> 25)\n",
       "      (3): Linear (25 -> 25)\n",
       "      (4): Linear (25 -> 2)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\n",
    "    train_data=train_data,\n",
    "    dev_data=dev_data,\n",
    "    model=model,\n",
    "    model_save_dir=\"data/models/modelstime/\",\n",
    "    num_iterations=250,\n",
    "    model_file_prefix=\"best_sopa\",\n",
    "    learning_rate=0.005,\n",
    "    batch_size=150,\n",
    "    num_classes=2,\n",
    "    patience=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/models/best_sopa.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_text = read_docs(test_file, vocab, num_padding_tokens=0)\n",
    "labels=read_labels(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = list(zip(test_input, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num predicted 1s: 295\n",
      "num gold 1s:      288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8500727802037845"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(model, test_data, batch_size=150, gpu=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
