{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "import tensorboardX\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"sopa_master/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import read_embeddings, read_docs, read_labels\n",
    "from soft_patterns import ProbSemiring, MaxPlusSemiring, LogSpaceMaxTimesSemiring, SoftPatternClassifier, train, Batch, evaluate_accuracy\n",
    "from util import to_cuda\n",
    "from interpret_classification_results import interpret_documents\n",
    "from visualize import visualize_patterns\n",
    "from baseline.dan import DanClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"data/time_data_clean/train.data\"\n",
    "train_label_file =\"data/time_data_clean/train.labels\"\n",
    "dev_data_file = \"data/time_data_clean/dev.data\"\n",
    "dev_label_file = \"data/time_data_clean/dev.labels\"\n",
    "test_file = \"data/time_data_clean/test.data\"\n",
    "test_label=\"data/time_data_clean/test.labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pickle.load(open(\"vocab.p\",\"rb\"))\n",
    "embeddings = pickle.load(open(\"embeddings.p\",\"rb\"))\n",
    "word_dim = pickle.load(open(\"word_dim.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# params: 3032\n"
     ]
    }
   ],
   "source": [
    "model=DanClassifier(\n",
    "    mlp_hidden_dim=10,\n",
    "    num_mlp_layers=2,\n",
    "    num_classes=2,\n",
    "    embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_text = read_docs(train_data_file, vocab, num_padding_tokens=1)\n",
    "train_labels = read_labels(train_label_file)\n",
    "dev_input, dev_text = read_docs(dev_data_file, vocab, num_padding_tokens=1)\n",
    "dev_labels = read_labels(dev_label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_input, train_labels))\n",
    "dev_data = list(zip(dev_input, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sopa_master/soft_patterns.py:502: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_softmax(output).view(batch.size(), num_classes),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............\n",
      "\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      317\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      207\n",
      "iteration:       0 train time:     0.017m, eval time:     0.008m train loss:        0.687 train_acc:   68.300% dev loss:        0.669 dev_acc:   64.433%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_0.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      330\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      207\n",
      "iteration:       1 train time:     0.042m, eval time:     0.008m train loss:        0.622 train_acc:   67.000% dev loss:        0.629 dev_acc:   64.433%\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_1.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      311\n",
      "num predicted 1s: 0\n",
      "num gold 1s:      207\n",
      "iteration:       2 train time:     0.067m, eval time:     0.009m train loss:        0.592 train_acc:   68.900% dev loss:        0.582 dev_acc:   64.433%\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_2.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 257\n",
      "num gold 1s:      318\n",
      "num predicted 1s: 180\n",
      "num gold 1s:      207\n",
      "iteration:       3 train time:     0.095m, eval time:     0.009m train loss:        0.549 train_acc:   76.900% dev loss:        0.550 dev_acc:   76.117%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_3.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 318\n",
      "num gold 1s:      322\n",
      "num predicted 1s: 200\n",
      "num gold 1s:      207\n",
      "iteration:       4 train time:     0.122m, eval time:     0.009m train loss:        0.522 train_acc:   77.000% dev loss:        0.517 dev_acc:   77.148%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_4.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 363\n",
      "num gold 1s:      325\n",
      "num predicted 1s: 237\n",
      "num gold 1s:      207\n",
      "iteration:       5 train time:     0.150m, eval time:     0.009m train loss:        0.501 train_acc:   78.000% dev loss:        0.510 dev_acc:   75.258%\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_5.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 252\n",
      "num gold 1s:      338\n",
      "num predicted 1s: 178\n",
      "num gold 1s:      207\n",
      "iteration:       6 train time:     0.177m, eval time:     0.009m train loss:        0.487 train_acc:   79.200% dev loss:        0.485 dev_acc:   77.148%\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_6.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 217\n",
      "num gold 1s:      319\n",
      "num predicted 1s: 149\n",
      "num gold 1s:      207\n",
      "iteration:       7 train time:     0.204m, eval time:     0.009m train loss:        0.488 train_acc:   80.200% dev loss:        0.485 dev_acc:   77.663%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_7.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 305\n",
      "num gold 1s:      317\n",
      "num predicted 1s: 194\n",
      "num gold 1s:      207\n",
      "iteration:       8 train time:     0.232m, eval time:     0.009m train loss:        0.507 train_acc:   80.600% dev loss:        0.472 dev_acc:   78.866%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_8.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 279\n",
      "num gold 1s:      317\n",
      "num predicted 1s: 180\n",
      "num gold 1s:      207\n",
      "iteration:       9 train time:     0.259m, eval time:     0.009m train loss:        0.458 train_acc:   80.400% dev loss:        0.467 dev_acc:   78.179%\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_9.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 272\n",
      "num gold 1s:      312\n",
      "num predicted 1s: 184\n",
      "num gold 1s:      207\n",
      "iteration:      10 train time:     0.287m, eval time:     0.009m train loss:        0.440 train_acc:   83.600% dev loss:        0.465 dev_acc:   77.835%\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_10.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 243\n",
      "num gold 1s:      335\n",
      "num predicted 1s: 162\n",
      "num gold 1s:      207\n",
      "iteration:      11 train time:     0.314m, eval time:     0.009m train loss:        0.434 train_acc:   81.600% dev loss:        0.464 dev_acc:   78.522%\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_11.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 258\n",
      "num gold 1s:      339\n",
      "num predicted 1s: 154\n",
      "num gold 1s:      207\n",
      "iteration:      12 train time:     0.342m, eval time:     0.009m train loss:        0.440 train_acc:   82.300% dev loss:        0.461 dev_acc:   79.553%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_12.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 224\n",
      "num gold 1s:      322\n",
      "num predicted 1s: 152\n",
      "num gold 1s:      207\n",
      "iteration:      13 train time:     0.370m, eval time:     0.009m train loss:        0.438 train_acc:   81.800% dev loss:        0.460 dev_acc:   78.179%\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_13.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 263\n",
      "num gold 1s:      317\n",
      "num predicted 1s: 167\n",
      "num gold 1s:      207\n",
      "iteration:      14 train time:     0.398m, eval time:     0.009m train loss:        0.409 train_acc:   82.600% dev loss:        0.448 dev_acc:   79.725%\n",
      "New best acc!\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_14.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 318\n",
      "num gold 1s:      312\n",
      "num predicted 1s: 205\n",
      "num gold 1s:      207\n",
      "iteration:      15 train time:     0.424m, eval time:     0.009m train loss:        0.409 train_acc:   82.800% dev loss:        0.444 dev_acc:   78.694%\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_15.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 155\n",
      "num gold 1s:      341\n",
      "num predicted 1s: 114\n",
      "num gold 1s:      207\n",
      "iteration:      16 train time:     0.452m, eval time:     0.009m train loss:        0.401 train_acc:   77.800% dev loss:        0.547 dev_acc:   77.148%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 204\n",
      "num gold 1s:      337\n",
      "num predicted 1s: 135\n",
      "num gold 1s:      207\n",
      "iteration:      17 train time:     0.479m, eval time:     0.009m train loss:        0.429 train_acc:   81.300% dev loss:        0.485 dev_acc:   77.663%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 258\n",
      "num gold 1s:      317\n",
      "num predicted 1s: 180\n",
      "num gold 1s:      207\n",
      "iteration:      18 train time:     0.506m, eval time:     0.009m train loss:        0.422 train_acc:   83.900% dev loss:        0.448 dev_acc:   79.210%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 317\n",
      "num gold 1s:      322\n",
      "num predicted 1s: 209\n",
      "num gold 1s:      207\n",
      "iteration:      19 train time:     0.534m, eval time:     0.009m train loss:        0.394 train_acc:   83.900% dev loss:        0.447 dev_acc:   78.694%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 295\n",
      "num gold 1s:      317\n",
      "num predicted 1s: 206\n",
      "num gold 1s:      207\n",
      "iteration:      20 train time:     0.561m, eval time:     0.009m train loss:        0.395 train_acc:   84.800% dev loss:        0.444 dev_acc:   78.522%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 347\n",
      "num gold 1s:      316\n",
      "num predicted 1s: 239\n",
      "num gold 1s:      207\n",
      "iteration:      21 train time:     0.589m, eval time:     0.009m train loss:        0.399 train_acc:   83.100% dev loss:        0.456 dev_acc:   76.976%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 361\n",
      "num gold 1s:      332\n",
      "num predicted 1s: 240\n",
      "num gold 1s:      207\n",
      "iteration:      22 train time:     0.616m, eval time:     0.009m train loss:        0.384 train_acc:   81.900% dev loss:        0.452 dev_acc:   76.117%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 297\n",
      "num gold 1s:      320\n",
      "num predicted 1s: 203\n",
      "num gold 1s:      207\n",
      "iteration:      23 train time:     0.643m, eval time:     0.008m train loss:        0.383 train_acc:   85.100% dev loss:        0.440 dev_acc:   79.038%\n",
      "New best dev!\n",
      "saving model to modeltimedan/traintimedan_23.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 290\n",
      "num gold 1s:      314\n",
      "num predicted 1s: 206\n",
      "num gold 1s:      207\n",
      "iteration:      24 train time:     0.667m, eval time:     0.008m train loss:        0.386 train_acc:   86.800% dev loss:        0.444 dev_acc:   78.179%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 231\n",
      "num gold 1s:      319\n",
      "num predicted 1s: 169\n",
      "num gold 1s:      207\n",
      "iteration:      25 train time:     0.691m, eval time:     0.008m train loss:        0.357 train_acc:   83.400% dev loss:        0.460 dev_acc:   80.069%\n",
      "New best acc!\n",
      "saving model to modeltimedan/traintimedan_25.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 331\n",
      "num gold 1s:      331\n",
      "num predicted 1s: 225\n",
      "num gold 1s:      207\n",
      "iteration:      26 train time:     0.715m, eval time:     0.008m train loss:        0.369 train_acc:   86.200% dev loss:        0.452 dev_acc:   77.320%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\n",
      "\n",
      "num predicted 1s: 379\n",
      "num gold 1s:      327\n",
      "num predicted 1s: 246\n",
      "num gold 1s:      207\n",
      "iteration:      27 train time:     0.739m, eval time:     0.008m train loss:        0.368 train_acc:   85.600% dev loss:        0.460 dev_acc:   75.086%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 309\n",
      "num gold 1s:      322\n",
      "num predicted 1s: 215\n",
      "num gold 1s:      207\n",
      "iteration:      28 train time:     0.764m, eval time:     0.008m train loss:        0.363 train_acc:   86.900% dev loss:        0.458 dev_acc:   77.320%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 249\n",
      "num gold 1s:      333\n",
      "num predicted 1s: 167\n",
      "num gold 1s:      207\n",
      "iteration:      29 train time:     0.789m, eval time:     0.008m train loss:        0.364 train_acc:   86.200% dev loss:        0.468 dev_acc:   78.694%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 263\n",
      "num gold 1s:      323\n",
      "num predicted 1s: 191\n",
      "num gold 1s:      207\n",
      "iteration:      30 train time:     0.813m, eval time:     0.008m train loss:        0.352 train_acc:   87.000% dev loss:        0.456 dev_acc:   79.038%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 366\n",
      "num gold 1s:      311\n",
      "num predicted 1s: 261\n",
      "num gold 1s:      207\n",
      "iteration:      31 train time:     0.838m, eval time:     0.008m train loss:        0.350 train_acc:   85.500% dev loss:        0.477 dev_acc:   75.601%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 326\n",
      "num gold 1s:      316\n",
      "num predicted 1s: 226\n",
      "num gold 1s:      207\n",
      "iteration:      32 train time:     0.863m, eval time:     0.008m train loss:        0.354 train_acc:   87.400% dev loss:        0.462 dev_acc:   76.460%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 386\n",
      "num gold 1s:      330\n",
      "num predicted 1s: 263\n",
      "num gold 1s:      207\n",
      "iteration:      33 train time:     0.887m, eval time:     0.008m train loss:        0.353 train_acc:   86.000% dev loss:        0.486 dev_acc:   74.227%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 286\n",
      "num gold 1s:      317\n",
      "num predicted 1s: 197\n",
      "num gold 1s:      207\n",
      "iteration:      34 train time:     0.911m, eval time:     0.008m train loss:        0.341 train_acc:   87.700% dev loss:        0.454 dev_acc:   77.663%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 260\n",
      "num gold 1s:      346\n",
      "num predicted 1s: 170\n",
      "num gold 1s:      207\n",
      "iteration:      35 train time:     0.936m, eval time:     0.008m train loss:        0.332 train_acc:   87.400% dev loss:        0.477 dev_acc:   80.241%\n",
      "New best acc!\n",
      "saving model to modeltimedan/traintimedan_35.pth\n",
      "....................\n",
      "\n",
      "num predicted 1s: 226\n",
      "num gold 1s:      318\n",
      "num predicted 1s: 179\n",
      "num gold 1s:      207\n",
      "iteration:      36 train time:     0.960m, eval time:     0.008m train loss:        0.335 train_acc:   85.400% dev loss:        0.478 dev_acc:   79.038%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 403\n",
      "num gold 1s:      312\n",
      "num predicted 1s: 287\n",
      "num gold 1s:      207\n",
      "iteration:      37 train time:     0.984m, eval time:     0.008m train loss:        0.337 train_acc:   84.900% dev loss:        0.513 dev_acc:   72.509%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 434\n",
      "num gold 1s:      320\n",
      "num predicted 1s: 297\n",
      "num gold 1s:      207\n",
      "iteration:      38 train time:     1.009m, eval time:     0.008m train loss:        0.330 train_acc:   84.600% dev loss:        0.529 dev_acc:   71.821%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 293\n",
      "num gold 1s:      311\n",
      "num predicted 1s: 208\n",
      "num gold 1s:      207\n",
      "iteration:      39 train time:     1.033m, eval time:     0.008m train loss:        0.347 train_acc:   89.800% dev loss:        0.460 dev_acc:   77.835%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 276\n",
      "num gold 1s:      346\n",
      "num predicted 1s: 189\n",
      "num gold 1s:      207\n",
      "iteration:      40 train time:     1.058m, eval time:     0.008m train loss:        0.349 train_acc:   86.800% dev loss:        0.475 dev_acc:   79.381%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 408\n",
      "num gold 1s:      325\n",
      "num predicted 1s: 290\n",
      "num gold 1s:      207\n",
      "iteration:      41 train time:     1.083m, eval time:     0.008m train loss:        0.329 train_acc:   85.900% dev loss:        0.515 dev_acc:   71.993%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 259\n",
      "num gold 1s:      327\n",
      "num predicted 1s: 190\n",
      "num gold 1s:      207\n",
      "iteration:      42 train time:     1.107m, eval time:     0.008m train loss:        0.335 train_acc:   88.200% dev loss:        0.471 dev_acc:   78.866%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 302\n",
      "num gold 1s:      323\n",
      "num predicted 1s: 216\n",
      "num gold 1s:      207\n",
      "iteration:      43 train time:     1.132m, eval time:     0.008m train loss:        0.313 train_acc:   89.100% dev loss:        0.471 dev_acc:   77.148%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 266\n",
      "num gold 1s:      315\n",
      "num predicted 1s: 198\n",
      "num gold 1s:      207\n",
      "iteration:      44 train time:     1.156m, eval time:     0.008m train loss:        0.305 train_acc:   88.100% dev loss:        0.475 dev_acc:   78.522%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 346\n",
      "num gold 1s:      313\n",
      "num predicted 1s: 245\n",
      "num gold 1s:      207\n",
      "iteration:      45 train time:     1.181m, eval time:     0.008m train loss:        0.308 train_acc:   89.500% dev loss:        0.493 dev_acc:   74.227%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 311\n",
      "num gold 1s:      305\n",
      "num predicted 1s: 222\n",
      "num gold 1s:      207\n",
      "iteration:      46 train time:     1.206m, eval time:     0.008m train loss:        0.312 train_acc:   89.400% dev loss:        0.488 dev_acc:   77.148%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 338\n",
      "num gold 1s:      309\n",
      "num predicted 1s: 241\n",
      "num gold 1s:      207\n",
      "iteration:      47 train time:     1.230m, eval time:     0.008m train loss:        0.299 train_acc:   88.300% dev loss:        0.492 dev_acc:   74.227%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 316\n",
      "num gold 1s:      333\n",
      "num predicted 1s: 209\n",
      "num gold 1s:      207\n",
      "iteration:      48 train time:     1.255m, eval time:     0.008m train loss:        0.293 train_acc:   90.300% dev loss:        0.482 dev_acc:   77.663%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 285\n",
      "num gold 1s:      309\n",
      "num predicted 1s: 205\n",
      "num gold 1s:      207\n",
      "iteration:      49 train time:     1.280m, eval time:     0.008m train loss:        0.295 train_acc:   90.200% dev loss:        0.481 dev_acc:   78.351%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 336\n",
      "num gold 1s:      318\n",
      "num predicted 1s: 233\n",
      "num gold 1s:      207\n",
      "iteration:      50 train time:     1.304m, eval time:     0.008m train loss:        0.290 train_acc:   91.200% dev loss:        0.492 dev_acc:   75.258%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 337\n",
      "num gold 1s:      320\n",
      "num predicted 1s: 244\n",
      "num gold 1s:      207\n",
      "iteration:      51 train time:     1.329m, eval time:     0.008m train loss:        0.301 train_acc:   89.500% dev loss:        0.502 dev_acc:   76.117%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 311\n",
      "num gold 1s:      325\n",
      "num predicted 1s: 210\n",
      "num gold 1s:      207\n",
      "iteration:      52 train time:     1.354m, eval time:     0.008m train loss:        0.303 train_acc:   91.000% dev loss:        0.500 dev_acc:   77.491%\n",
      "....................\n",
      "\n",
      "num predicted 1s: 280\n",
      "num gold 1s:      326\n",
      "num predicted 1s: 204\n",
      "num gold 1s:      207\n",
      "iteration:      53 train time:     1.378m, eval time:     0.008m train loss:        0.296 train_acc:   89.400% dev loss:        0.493 dev_acc:   78.522%\n",
      "Reached 30 iterations without improving dev loss. Breaking\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DanClassifier(\n",
       "  (mlp): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=300, out_features=10, bias=True)\n",
       "      (1): Linear(in_features=10, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\n",
    "    train_data=train_data,\n",
    "    dev_data=dev_data,\n",
    "    model=model,\n",
    "    model_save_dir=\"data/models/modeltimedan/\",\n",
    "    num_iterations=250,\n",
    "    model_file_prefix=\"traintimedan\",\n",
    "    learning_rate=0.05,\n",
    "    batch_size=150,\n",
    "    num_classes=2,\n",
    "    patience=30,\n",
    "    gpu=False,\n",
    "    word_dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"data/models/modeltimedan.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_text = read_docs(test_file, vocab, num_padding_tokens=3)\n",
    "labels=read_labels(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = list(zip(test_input, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num predicted 1s: 232\n",
      "num gold 1s:      232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8101788170563962"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(model, test_data, batch_size=150, gpu=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
